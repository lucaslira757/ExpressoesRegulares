import json
import csv
import re
import requests


r = requests.get('https://www.pensador.com/autor/machado_de_assis/')
site = r.text

frase = re.findall(r'<p class="frase \w+" id=".+">.+</p>',site)
autor = re.findall(r'<span class="autor">\n.+</span>',site)
Share = re.findall(r'<div class="total-shares">.+<span>',site)

lista = [[],[],[]]

for x in frase:
    for le in range(len(x)):
        if x[le] == '>':
            lista[0].append(x[le+1:len(x)-4])
            break

for x in autor:
    for le in range(len(x)):
        if x[le:le+1] == "\n":
            lista[1].append(x[le+1:len(x)-7])
            break
for x in Share:
    for le in range(len(x)):
        if x[le] == '>':
            lista[2].append(x[le+1:len(x)-6])
            break
aux = []
for i in range(len(frase)):
    aux2 = {'frase':lista[0][i],'autor':lista[1][i],'Share':lista[2][i]}
    aux.append(aux2)
aux3 = {'frases':aux}
            

with open('arquivo.json' , 'w', encoding="utf8") as f:
    json.dump(aux3, f , ensure_ascii=False)


with open('dados.csv', 'w', newline='') as csvfile:
    spamwriter = csv.writer(csvfile, delimiter=';')
    spamwriter.writerow(['FRASE','AUTOR','COMPARTILHAMENTOS'])
    for x in range(len(frase)):
        spamwriter.writerow([lista[0][x],lista[1][x],lista[2][x]])
